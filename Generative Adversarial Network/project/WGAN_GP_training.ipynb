{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc5UaXX-7ewy"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 저장할 폴더 생성\n",
        "if not os.path.exists('checkpoints'):\n",
        "  os.makedirs('checkpoints')\n"
      ],
      "metadata": {
        "id": "Mugh-WCf73Yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 출력 저장할 폴더 생성\n",
        "if not os.path.exists('outputs'):\n",
        "  os.makedirs('outputs')"
      ],
      "metadata": {
        "id": "Ih5qb8vv8ATV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator networks - 구분자!!! 참, 거짓만 밝혀내면 되므로 출력은 1차원이면 됨\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_dim=3,  dim=64):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    def conv_ln_lrelu(in_dim, out_dim):\n",
        "      return nn.Sequential(\n",
        "          nn.Conv2d(in_dim, out_dim, 5, 2, 2),\n",
        "          # LayerNorm의 효과는 여기서는 효과가 없기 때문에\n",
        "          # LayerNorm 대신, InstanceNorm2d를 활용\n",
        "          nn.InstanceNorm2d(out_dim, affince=True),\n",
        "          nn.LeakyReLU(0.2)\n",
        "      )\n",
        "    self.ls = nn.Sequential(\n",
        "        nn.Conv2d(in_dim, dim, 5, 2, 2),\n",
        "        nn.LeakyReLU(0, 2),\n",
        "        conv_ln_lrelu(dim, dim*2),\n",
        "        conv_ln_lrelu(dim*2, dim*4),\n",
        "        conv_ln_lrelu(dim*4, dim*8),\n",
        "        nn.Conv2d(dim*8, 1, 4),\n",
        "\n",
        "    )\n",
        "  # 이제 discriminator는 0, 1로 참, 거짓을 판별하는 대신\n",
        "  def forward(self, x):\n",
        "    y = self.ls(x)\n",
        "    y = y.view(-1)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "ejnCRg4o8HJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator networks\n",
        "class Generator(nn.Module):\n",
        "\n",
        "  def __init__(self, in_dim=128, dim=64):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    def dconv_bn_relu(in_dim, out_dim):\n",
        "      return nn.Sequential(\n",
        "          nn.ConvTranspose2d(in_dim, out_dim, 5, 2, padding=2, output_padding=1, bias=False),\n",
        "          nn.BatchNorm2d(out_dim),\n",
        "          nn.ReLU()\n",
        "      )\n",
        "\n",
        "    self.l1 = nn.Sequential(\n",
        "        nn.Linear(in_dim, dim * 8 * 4 * 4, bias=False),\n",
        "        nn.BatchNorm1d(dim * 8 * 4 * 4),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.l2_5 = nn.Sequential(\n",
        "        dconv_bn_relu(dim*8, dim*4),\n",
        "        dconv_bn_relu(dim*4, dim*2),\n",
        "        dconv_bn_relu(dim*2, dim),\n",
        "        nn.ConvTranspose2d(dim, 3, 5, 2, padding=2, output_padding=1),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.l1(x)\n",
        "    y = y.view(y.size(0), -1, 4, 4)\n",
        "    y = self.l2_5(y)\n",
        "    return y"
      ],
      "metadata": {
        "id": "CGPrhRQD80bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(img, renorm=False, nrow=8, interpolation='bicubic'):\n",
        "  if renorm:\n",
        "    img = img*0.5 + 0.5\n",
        "  img_grid = torchvision.utils.make_grid(img, nrow=nrow).numpy()\n",
        "  plt.figure()\n",
        "  plt.imshow(np.transpose(img_grid, (1,2,0)), interpolation=interpolation)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "VNLNucgU9rEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'data_faces/img_aling_celeba'\n",
        "img_list = os.listdir(root)\n",
        "print(len(img_list))"
      ],
      "metadata": {
        "id": "UWFSyGNU-Py6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crop_size = 128\n",
        "re_size=64\n",
        "\n",
        "offset_height = (218 - crop_size) // 2\n",
        "offset_width = (178 - crop_size) // 2\n",
        "crop = lambda x: x[:, offset_height:offset_height + crop_size, offset_width:offset_width + crop_size]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(crop),\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(size=(re_size, re_size), interpolation=Image.BICUBIC),\n",
        "    transforms.ToTensor()\n",
        "    transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3)\n",
        "])\n",
        "\n",
        "batch_size = 64\n",
        "celeba_data = datasets.ImageFolder('./data_faces', transform=transform)\n",
        "celeba_loader= DataLoader(celeba_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "sG6X98mT-WgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch, _ = next(iter(celeba_loader))\n",
        "show(batch[0:16], nrow=4)"
      ],
      "metadata": {
        "id": "Fs2PHkjh-xjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "HhQ3Q2GY8viC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model weights를 초기화하는 함수\n",
        "def initialize_weights(model):\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "      nn.init.normal_(m.weight.data, 0.0, 0.02), # 평균 0, 분산 0.02\n",
        "    if isinstance(m, nn.ConvTranspose2d):\n",
        "      nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "      nn.init.normal_(m.weight.data, 0.0, 0.02)"
      ],
      "metadata": {
        "id": "3LXIC9yFUqEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자, 판별자 만들기\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "initialize_weights(generator)\n",
        "initialize_weights(discriminator)\n",
        "\n",
        "# loss 함수 설정\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "UDRf00SV-3bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE 훈련\n",
        "num_epochs = 50\n",
        "latent_dim = 128\n",
        "\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "lambda_gp = 10\n",
        "n_critic = 5 # 이 숫자는 generator 훈련하기 전에 discriminator 훈련을 몇 번씩 끊어 돌릴 건지 결정함\n",
        "num_steps = 0\n",
        "\n",
        "# 훈련 루프\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (real_images, _) in enumerate(celeba_loader):\n",
        "\n",
        "    real_images = real_images.to(device)\n",
        "    batch_size = real_images.size(0)\n",
        "\n",
        "    #Discriminator 훈련\n",
        "    for _ in range(n_critic):\n",
        "      # Discriminator 훈련\n",
        "      optimizer_D.zero_grad()\n",
        "\n",
        "      # Discriminator의 실제 그림 출력물\n",
        "      D_real = discriminator(real_images)\n",
        "      D_real_loss = torch.mean(D_real)\n",
        "\n",
        "      # Generator가 가짜 그림을 만들고, discriminator가 결과물 확인하기\n",
        "      z = torch.randn(batch_size, latent_dim).cuda()\n",
        "      fake_images = generator(z)\n",
        "      D_fake = discriminator(fake_images)\n",
        "      D_fake_loss = torch.mean(D_fake)\n",
        "\n",
        "      # gradient penalty 계산\n",
        "      alpha = torch.rand(batch_size, 1, 1, 1).cuda()\n",
        "      x_hat = alpha * real_images.data + (1 - alpha) * fake_images.data\n",
        "      x_hat.requires_grad = True\n",
        "      pred_hat = discriminator(x_hat)\n",
        "      gradients = torch.autograd.grad(output=pred_hat, input=x_hat, grad_outputs=torch.ones(pred_hat.size()).cuda(),\n",
        "                                      create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "      gradient_penalty = lambda_gp * torch.mean((1. - torch.sqrt(1e-8*torch.sum(gradients.view(gradients.size(0), -1)**2, dim=1)))**2) # torch.sqrt(torch.sum(gradients **2, dim=1) + 1e-12).mean()\n",
        "\n",
        "      # total discriminator loss\n",
        "      D_loss = D_fake_loss - D_real_loss + gradient_penalty\n",
        "      D_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "    # Generator 훈련\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    # 거짓 그림 만들고, discriminator의 출력 확인\n",
        "    z = torch.randn(batch_size, latent_dim).cuda()\n",
        "    fake_images = generator(z)\n",
        "    D_fake = discriminator(fake_images)\n",
        "    G_loss = -torch.mean(D_fake)\n",
        "\n",
        "    G_loss.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "    # loss를 더해두기\n",
        "    D_losses.append(D_loss.item())\n",
        "    G_losses.append(G_loss.item())\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print(f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{celeba_loader}]\")\n",
        "      print(f\"D Loss: {D_loss.item()}\")\n",
        "      print(f\"G Loss: {G_loss.item()}\")\n",
        "      with torch.no_grad():\n",
        "        fake_images = fake_images.detach().cpu().permute(0,2,3,1)/2\n",
        "        fake_images += 0.5\n",
        "        fake_images = fake_images.clip(0,1).numpy()\n",
        "        fig, axs = plt.subplots(5, 5)\n",
        "        cnt = 0\n",
        "        for i in range(5):\n",
        "          for j in range(5):\n",
        "            axs[i, j].imshow(fake_images[cnt])\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "        plt.savefig(os.path.join(\"outputs\", f\"gan_images_epoch_{epoch}.png\"))\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "torch.save(generator.state_dict(), os.path.join('checkpoints', f'G_{epoch}.png'))\n",
        "torch.save(discriminator.state_dict(), os.path.join('checkpoints', f'D_{epoch}.png'))\n"
      ],
      "metadata": {
        "id": "iB2XGN-d800J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}