{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf43yGZToljv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import pickle\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "import sys\n",
        "import bz2\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "jOWlD1_Ko6FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LandmarksDetector:\n",
        "  def __init__(self, predictor_model_path):\n",
        "    \"\"\"\n",
        "    :param predictor_model_path: path to shape_predictor_68_face_landmarks.dat file\n",
        "    \"\"\"\n",
        "    self.detector = dlib.get_frontal_face_detector() # 얼굴 인식 모델\n",
        "    self.shape_predictor = dlib.shape_predictor(predictor_model_path) # 얼굴 특징점 인식 모델\n",
        "\n",
        "  def get_landmarks(self, image):\n",
        "    \"\"\"\n",
        "    :param image: input image with detected face\n",
        "    :return: landmarks: landmarks detected in image\n",
        "    \"\"\"\n",
        "    img = dlib.load_rgb_image(image)\n",
        "    dets = self.detector(img, 1)\n",
        "\n",
        "    for detection in dets:\n",
        "      try:\n",
        "        face_landmarks = [(item.x, item.y) for item in self.shape_predictor(img, detection).parts()]\n",
        "        yield face_landmarks\n",
        "      except:\n",
        "        print(\"Exception in get_landmarks()\")\n"
      ],
      "metadata": {
        "id": "dZsqQyQUpA41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p raw\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/0/0e/Donald_Trump_Pentagon_2017.jpg -0 raw/example.jpg"
      ],
      "metadata": {
        "id": "i-x5-udNrWeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LANDMARKS_MODEL_URL = 'http://lib.net/files/shape_predictor_68_face_landmarks.dat.bz2'\n",
        "\n",
        "def unpack_bz2(src_path):\n",
        "  data = bz2.BZ2File(src_path).read()\n",
        "  dst_path = src_path[:-4]\n",
        "  with open(dst_path, 'wb') as fp:\n",
        "    fp.write(data)\n",
        "  return dst_path"
      ],
      "metadata": {
        "id": "Oja8qIPgrigD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "landmarks_model_path = unpack_bz2(get_file('shape_predictor_68_face_landmarks.dat.bz2', LANDMARKS_MODEL_URL, cache_subdir='temp'))"
      ],
      "metadata": {
        "id": "xMiCiQXbuxKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "landmarks_detector = LandmarksDetector(landmarks_model_path)"
      ],
      "metadata": {
        "id": "pbtpi-DGu6gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_img_path = 'raw/example.jpg'\n",
        "face_landmraks = next(landmarks_detector.get_landmarks(raw_img_path))"
      ],
      "metadata": {
        "id": "3ofLrYCxw4YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = np.array(face_landmarks)"
      ],
      "metadata": {
        "id": "vA32NoSqxAg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.flip(cv2.imread(raw_img_path), -1)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.savefig('1.png', bbox_inches='tight', transparent='True', pad_inches=0)"
      ],
      "metadata": {
        "id": "2kifJ3FQxDJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)\n",
        "plt.scatter(lm[:,0], lm[:,1])\n",
        "plt.axis('off')\n",
        "plt.savefig('2.png', bbox_inches='tight', transparent='True', pad_inches=0)"
      ],
      "metadata": {
        "id": "glYgZwD0xPgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_chin = lm[0:17]\n",
        "lm_eyebrow_left = lm[17:22]\n",
        "lm_eyebrow_right = lm[22:27]\n",
        "lm_nose = lm[27:31]\n",
        "lm_nostrils = lm[31:36]\n",
        "lm_eye_left = lm[36:42]\n",
        "lm_eye_right = lm[42:48]\n",
        "lm_mouth_outer = lm[48:60]\n",
        "lm_mouth_inner = lm[60:68]"
      ],
      "metadata": {
        "id": "QJnGTidv0Mcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)\n",
        "for M in [lm_chin, lm_eyebrow_left, lm_eyebrow_right, lm_nose, lm_nostrils, lm_eye_left, lm_eye_right, lm_mouth_outer, lm_mouth_inner]:\n",
        "  plt.scatter(M[:,0], M[:,1])\n",
        "plt.axis('off')\n"
      ],
      "metadata": {
        "id": "rfVcRw0M0jEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성을 변경할 vector를 계산하기\n",
        "eye_left = np,mean(lm_eye_left, axis=0)\n",
        "eye_right = np.mean(lm_eye_right, axis=0)\n",
        "eye_avg = (eye_left + eye_right) * 0.5\n",
        "eye_to_eye = eye_right - eye_left\n",
        "mouth_left = lm_mouth_outer[0]\n",
        "mouth_right = lm_mouth_outer[6]\n",
        "mouth_avg = (mouth_left + mouth_right) * 0.5\n",
        "eye_to_mouth = mouth_avg - eye_avg"
      ],
      "metadata": {
        "id": "J9gpn_XK9bjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)\n",
        "plt.scatter(eye_left[0], eye_left[1], c='b')\n",
        "plt.scatter(eye_right[0], eye_right[1], c='b')\n",
        "plt.scatter(eye_avg[0], eye_avg[1], c='b')\n",
        "\n",
        "plt.scatter(mouth_left[0], mouth_left[1], c='b')\n",
        "plt.scatter(mouth_right[0], mouth_right[1], c='b')\n",
        "plt.scatter(mouth_avg[0], mouth_avg[1], c='b')\n",
        "\n",
        "plt.plot(mouth_avg[0], eye_avg[0], (mouth_avg[1], eye_avg[1]), c='r')\n",
        "plt.axis('off')\n",
        "plt.savefig('4.png', bbox_inches='tight', transparent='True', pad_inches=0)\n"
      ],
      "metadata": {
        "id": "GUBFa3UF9kn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_size=1024\n",
        "transform_size = 4096\n",
        "enable_padding=True\n",
        "x_scale=1\n",
        "y_scale=1\n",
        "em_scale=0.1\n",
        "alpha=False"
      ],
      "metadata": {
        "id": "g05WdrnE_9Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘라낼 네모 고르기\n",
        "x = eye_to_eye - np.flipud(eye_to_mouth) * [-1, 1]\n",
        "x /= np.hypot(*x)\n",
        "x *= max(np.hypot(*eye_to_eye) * 2.0, np.hypot(*eye_to_mouth) * 1.8)\n",
        "x *= x_scale\n",
        "y = np.flipud(x) * [-y_scale, y_scale]\n",
        "c = eye_avg + eye_to_mouth * em_scale\n",
        "quad = np.stack((c-x-y, c-x+y, c+x+y, c+x-y))\n",
        "qsize = np.hypot(*x) * 2"
      ],
      "metadata": {
        "id": "lb6MymMsAH62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_min, y_min = np.min(quad, 0)\n",
        "w, h = np.max(quad, 0) - np.min(quad, 0)"
      ],
      "metadata": {
        "id": "JzOQ-vGXAsPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplot()\n",
        "plt.imshow(img)\n",
        "\n",
        "rect = patches.Rectangle((x_min, y_min), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
        "ax.add_patch(rect)\n",
        "plt.axis('off')\n",
        "plt.savefig('5.png', bbox_inches='tight', transparent='True', pad_inches=0)"
      ],
      "metadata": {
        "id": "1yglfhFRA0mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open(raw_img_path).convert('RGBA').convert('RGB')\n",
        "\n",
        "shrink = int(np.floor(qsize / output_size * 0.5))\n",
        "if shrink > 1:\n",
        "  rsize = (int(np.round(float(img.size[0]) / shrink)), int(np.round(float(img.size[1]) / shrink)))\n",
        "  img = img.resize(rsize, Image.ANTIALIAS)\n",
        "  quad /= shrink\n",
        "  qsize /= shrink"
      ],
      "metadata": {
        "id": "JVg_djh4BDb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "border = max(int(np.rint(qsize * 0.1)), 3)\n",
        "crop = (int(np.floor(min(quad[:,0]))), int(np.floor(min(quad[:,1]))), int(np.ceil(max(quad[:,0]))), int(np.ceil(max(quad[:,1]))))\n",
        "crop = (max(crop[0] - border, 0), max(crop[1] - border, 0), min(crop[2] + border, img.size[0]), min(crop[3] + border, img.size[1]))\n",
        "if crop[2] - crop[0] < img.size[0] or crop[3] - crop[1] < img.size[1]:\n",
        "  img = img.crop(crop)\n",
        "  quad -= crop[0:2]"
      ],
      "metadata": {
        "id": "rdixZNvBBTy9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}