{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 그림 생성\n"
      ],
      "metadata": {
        "id": "euYtVFu7d6Zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install click requests tqdm pyspng ninja imageio-ffmpeg=-0.4.3"
      ],
      "metadata": {
        "id": "JIsD_rNJedkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 훈련된 모델 가져오기"
      ],
      "metadata": {
        "id": "wPERnkS5el03"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tLliF1Yd3TS"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stylegan2-ada-pytorch/\n",
        "!wget -nc https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\n",
        "%cd .."
      ],
      "metadata": {
        "id": "WegK-9eLeDnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그림 생성, 저장"
      ],
      "metadata": {
        "id": "6IBt18LaePSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, pickle\n",
        "import functools\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "fKM37z24eRwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models, transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from os.path import isfile\n",
        "import json\n",
        "import argparse\n",
        "from sklearn.svm import LinearSVC"
      ],
      "metadata": {
        "id": "YX9IDhVEe2rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stylegan2-ada-pytorch"
      ],
      "metadata": {
        "id": "2oGVDSDXfHOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device_name)\n",
        "\n",
        "with open('ffhq.pkl', 'rb') as f:\n",
        "  G = pickle.load(f)['G_ema'].to(device)\n",
        "if device_name == \"cpu\":\n",
        "  G.synthesis.forward = functools.partial(G.synthesis.forward, force_fp32=True)\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "id": "m-eicPDvfJux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test_UnlabeledImages\n",
        "!mkdir test_ImageLatentCodes"
      ],
      "metadata": {
        "id": "YfI5Y8b5fjLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 10\n",
        "\n",
        "for k in tqdm(range(N)):\n",
        "  with torch.inference_mode():\n",
        "    z = torch.randn([1, G.z_dim]).to(device)\n",
        "    torch.save(z, f'test_ImageLatentCodes/tensor{k}.pt')\n",
        "    Image = (0.5*(G(z, None)[0]+1)).cpu().detach().numpy().clip(0,1)\n",
        "    plt.imsave(f'test_UnlabeledImages/img{k}.jpg', image.transpose(1,2,0))"
      ],
      "metadata": {
        "id": "o0RRD4qoft0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = image.transpose(1,2,0)"
      ],
      "metadata": {
        "id": "jHGT4YWOgOYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image)\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "piCUxSRtgRm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator 불러오기"
      ],
      "metadata": {
        "id": "7TzteLErjvUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(device_name)\n",
        "print(device)"
      ],
      "metadata": {
        "id": "wseJYaFPjzAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientNetB0(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(EfficientNetB0, self).__init__()\n",
        "    self.model = models.efficientnet_b0(pretrained=True)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "    self.head = nn.Sequential(\n",
        "        nn.Linear(1280, 1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(1024, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(256, 40)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model.features(x)\n",
        "\n",
        "    x = self.avgpool(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "IShiyELsj7t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://github.com/GurvanR/GANSpace-Reimplementation/raw/main/atclas2.pt"
      ],
      "metadata": {
        "id": "679x2L2sgcmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "net = EfficientNetB0()\n",
        "net.load_state_dict(torch.load('atclas2.pt'))\n",
        "net = net.to(device)\n",
        "net.eval()"
      ],
      "metadata": {
        "id": "QCpfMC6TnBRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "classification"
      ],
      "metadata": {
        "id": "nHqf8JXAodQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1hY3zxdC9gf4-R4xfDONiJPpaOddq2yr"
      ],
      "metadata": {
        "id": "Xj_p-Og-nL-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('list_attr_celeba.csv')\n",
        "\n",
        "att_names = np.array(list(df.columns[1:]))"
      ],
      "metadata": {
        "id": "fNZNEmXgongi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.from_numpy(image).float().cuda().unsqueeze(0).permute(0,3,1,2)\n",
        "batch.shape"
      ],
      "metadata": {
        "id": "i048D4ROowB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = net(batch).detach().cpu()\n"
      ],
      "metadata": {
        "id": "3zY1OCvsoyHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sigmoid(out.view(-1))>0.5"
      ],
      "metadata": {
        "id": "X-DadbDdpAWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,u in enumerate(torch.sigmoid(out.view(-1))>0.5):\n",
        "  if u:\n",
        "    print(att_names[i])"
      ],
      "metadata": {
        "id": "AVr32LsHpEIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_classification(dataset_path, output_path, proportion, batch_size=10):\n",
        "  if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "  if not os.path.isdir(output_path):\n",
        "    raise ValueError(\"Output path muse be a directory, not overwriting existing file\")\n",
        "\n",
        "  filenames = [f for f in os.listdir(dataset_path) if isfile(os.path.join(dataset_path, f))]\n",
        "  filenames_and_scores = [[] for _ in range(40)]\n",
        "  totensor = transforms.ToTensor()\n",
        "\n",
        "  for i in tqdm(range(0, len(filenames), batch_size)):\n",
        "    batch = torch.zeros((batch_size, 3, 1024, 1024))\n",
        "    batch_filenames = filenames[i:min(i+batch_size, len(filenames))]\n",
        "    for j, f in enumearte(batch_filenames):\n",
        "      path = os.path.join(dataset_path, f)\n",
        "      if not isfile(path):\n",
        "        continue\n",
        "      img = Image.open(path)\n",
        "      batch[j] = 255+totensor(img)\n",
        "      img.close()\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    # batch 내용을 network에 저장하기\n",
        "    with torch.inference_mode():\n",
        "      out = net(batch).cpu()\n",
        "    for j, f in enumerate(batch_filenames):\n",
        "      for att in range(40):\n",
        "        filenames_and_scores[att].append((f, out[j, att].item()))\n",
        "  # 결과를 json 파일에 저장하기\n",
        "  for att in range(40):\n",
        "    with open(os.path.join(output_path, f\"att{att}_scores.json\"), \"w\") as outfile:\n",
        "      json.dump(dict(filenames_and_scores[att]), outfile)\n",
        "\n",
        "    # classes를 생성하고 연관성 있는 특성들로 구분하기!\n",
        "    filenames_and_scores[att].sort(key=lambda p: p[1])\n",
        "    num_top = int(proportion*len(filenames)/100)\n"
      ],
      "metadata": {
        "id": "MnvEoWczpOuD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proportion = 2\n",
        "\n",
        "dataset_path = 'test_UnlabeledImages'\n",
        "output_path = 'Labels'\n",
        "\n",
        "run_classification(dataset_path, output_path, proportion)"
      ],
      "metadata": {
        "id": "mBeWb3pWYhNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_classification(dataset_path, output_path, proportion)"
      ],
      "metadata": {
        "id": "kj8Po99GXgBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieving labeled latent vectors\n",
        "\n",
        "Double-cliquez"
      ],
      "metadata": {
        "id": "osdIbBHFYuyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attribute_numbers=[np.where(att_names==u)[0][0] for u in ['Smiling', 'Young', 'Eyeglasses', 'Male', 'Mustache']]"
      ],
      "metadata": {
        "id": "LBQBJfmsY2ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attribute_numbers"
      ],
      "metadata": {
        "id": "nsN0wlaOZFV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_vectors_path = 'test_ImageLatentCodes'"
      ],
      "metadata": {
        "id": "u3IxPWyHZKM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for attribute_number in attribute_numbers:\n",
        "  labels_path = f'Labels/att{str(attribute_number)}_labels.json'\n",
        "  with open(labels_path, 'r') as f:\n",
        "    labels_dict = json.load(f)\n",
        "\n",
        "  num_samples = len(labels_dict)\n",
        "  dim = 512\n",
        "  Z = torch.zeros((num_samples, dim)).to(device)\n",
        "  y = np.zeros(num_samples, dtype=int)\n",
        "\n",
        "  for i, (filename, label) in tqdm(emumerate(labels_dict.items())):\n",
        "    sample_number = int(filename[3:-4])\n",
        "    tensor_path = f'test_ImageLatentCodes/tensor{sample_number}.pt'\n",
        "    Z[i] = torch.load(tensor_path, map_location=device)\n",
        "    y[i] = label\n",
        "\n",
        "  # SVM\n",
        "\n",
        "  Z_forSVM = z.cpu().numpy()\n",
        "\n",
        "  linear_svm_Z = LinearSVC()\n",
        "  linear_svm_z.fit(Z_forSVM, y)\n",
        "  # orthogonal vector를 얻기 - svm을 통해 만들어진 하이퍼 평면의 벡터\n",
        "  class_direction_Z = torch.Tensor(linear_svm_Z.coef_[0])\n",
        "\n",
        "  Z_intercept = torch.Tensor(linear_svm_Z.intercept_)\n",
        "\n",
        "  W = G.mapping(Z, None)\n",
        "\n",
        "  W_for_SVM = W[:,0,:].cpu().numpy()\n",
        "\n",
        "  linear_svm_W = LinearSVC()\n",
        "  linear_svm_W.fit(W_for_SVM, y)\n",
        "\n",
        "  class_direction_W = torch.Tensor(linear_svm_W.coef_[0])\n",
        "\n",
        "  W_intercept = torch.Tensor(linear_svm_W.intercept_)\n",
        "\n",
        "  if not os.path.exists('SVM_vectors'):\n",
        "    os.makedirs('SVM_vectors')\n",
        "\n",
        "  torch.save(class_direction_Z, f'SVM_vectors/class_direction_Z_on_3k_att{attribute_number}.pt')\n",
        "  torch.save(class_direction_W, f'SVM_vectors/class_direction_W_on_3k_att{attribute_number}.pt')\n",
        "\n",
        "  torch.save(Z_intercept, f'SVM_vectors/Z_intercept_on_3k_att{attribute_number}.pt')\n",
        "  torch.save(W_intercept, f'SVM_vectors/W_intercept_on_3k_att{attribute_number}.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "H4X1l8Q_ZP7B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}