{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvPq-JVn9_G0"
      },
      "outputs": [],
      "source": [
        "# Mnist라는 숫자를 그림으로 표현한 것을 학습시킬 것 기존의 autoencoder구조를 개선한 것을 적용하기!\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_dim=128"
      ],
      "metadata": {
        "id": "YKMUfP2r-TD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# autoencoder model 정의\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, z_dim=128):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    # Encoder\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Conv2d(1, 16, 3, stride=1, padding=1), # 32 x 28 x 28\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(16, 32, 3, stride=2, padding=1), # 64 x 14 x 14\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(32, 64, 3, stride=2, padding=1), # 64 x 7 x 7\n",
        "        nn.ReLU(True)\n",
        "    )\n",
        "    # Latent space\n",
        "    self.latent_space = nn.Linear(64*7*7, z_dim)\n",
        "    # Decoder\n",
        "    self.decoder_mlp = nn.Sequential(\n",
        "        nn.Linear(z_dim, 64*7*7),\n",
        "        nn.ReLU(True),\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1), # 7 x 7 x 32\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(32, 16, 4, stride=2, padding=1), # 14 x 14 x 16\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(16, 1, 3, stride=1, padding=1), # 28 x 28 x 1\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def reparameterize(self, mu, logvar):\n",
        "    std = torch.exp(0.5*logvar)\n",
        "    eps = torch.rand_like(std)\n",
        "    return mu + eps*std\n",
        "\n",
        "\n",
        "  def encoding(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = x.reshape(x.size(0), -1) # flatten the tensor\n",
        "    latent_params = self.latent_space(x)\n",
        "    mu, logvar = torch.chunk(latent_params, 2, dim=1)\n",
        "    return mu, logvar\n",
        "\n",
        "  def decoding(self, x):\n",
        "    x = self.decoder_mlp(x).view(x.size(0), 64, 7, 7)\n",
        "    x = self.decoder(x) # tensor 차원 수정\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    # print(x.shape)\n",
        "    x = x.reshape(x.size(0), -1) # flatten the tensor\n",
        "    # print(x.shape)\n",
        "    latent_params = self.latent_space(x)\n",
        "\n",
        "    mu, logvar = torch.chunk(latent_params, 2, dim=1)\n",
        "    z = self.reparameterize(mu, logvar)\n",
        "\n",
        "    # print(x.shape)\n",
        "    x = self.decoder_mlp(z).view(x.size(0), 64, 7, 7)\n",
        "    # print(x.shape)\n",
        "    x = self.decoder(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "p74EurUb-Uf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(x_hat, x, mean, log_var, k1, k2):\n",
        "  reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
        "  KLD = -0.5*torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
        "  return k1*reproduction_loss + k2*KLD"
      ],
      "metadata": {
        "id": "tbMpXRTC4KA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset 불러오기! > 아래의 내용은 기본적으로 tensor로 변환만 하고 있음 > MNIST는 이미 데이터 기본 전처리가 되어있기 때문\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "w5GYFKUYA8jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(route='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(route='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "ow8Z8rE02hp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 클래스별로 저장된 파일을 담을 dict 만들기\n",
        "samples = {}\n",
        "for i in range(10):\n",
        "  samples[i] = None\n",
        "\n",
        "cpt = 0\n",
        "\n",
        "# 훈련용 데이터에 들어있는 정보를 클래스별로 저장해두기\n",
        "for data, target in train_dataset:\n",
        "  if samples[target] is None:\n",
        "    samples[target] = data\n",
        "    cpt += 1\n",
        "    if cpt == 10:\n",
        "      break\n",
        "\n",
        "# sample 그리기\n",
        "fig, axes = plt.subplots(1, 10, figsize=(12, 3))\n",
        "for i in range(10):\n",
        "  axes[i].imshow(samples[i][0], cmap='gray')\n",
        "  axes[i].set_title(f'Class {i}')\n",
        "  axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x17TFLaS37Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 만들기\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "#\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "-b9O7NgW4ysL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )"
      ],
      "metadata": {
        "id": "qrnxvIxP7rtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "#AutoEncoder model을 이용하여 모델 객체 만들고\n",
        "# 특정 device로 불러오기 - cpu, gpu 중에 선택\n",
        "model = Autoencoder(z_dim).to(device)\n",
        "\n",
        "# optimizer 객체 만들기\n",
        "# 일반적으로 Adam을 많이 사용함..\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# loss 정의\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "PXBTdPJr71R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor의 모습 확인할 것 - 이것은 코드를 작성하는 과정에서만 잠시 임의로 쓰이는 부분\n",
        "# I = torch.rand((1,1,28,28)).cuda()\n",
        "# with torch.no_grad():\n",
        "#  print(model(I).shape)"
      ],
      "metadata": {
        "id": "eghAKmw18Xl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k1, k2 = 1, 1\n",
        "# 훈련\n",
        "num_epochs = 100\n",
        "train_losses = []\n",
        "for epoch in range[num_epochs]:\n",
        "  running_loss = 0.0\n",
        "  for images, _ in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs, mu, logvar = model(images.float().cuda())\n",
        "    loss = loss_function(outputs, images.float().cuda(), mu, logvar, k1, k2)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item() * images.size(0)\n",
        "  train_loss = running_loss / len(train_loader.dataset)\n",
        "  train_losses.append(train_loss)\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "IuSluyG38pgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random images를 선택하고 그 테스트 이미지들을 재구성하기\n",
        "# 만약 재구성된 그림의 품질이 좋지 않으면? > latent space의 크기를 늘려볼 것!\n",
        "\n",
        "num_images = 5\n",
        "\n",
        "selected_indices = torch.randint(len(test_dataset), size=(num_images,))\n",
        "reconstructed_images = []\n",
        "original_images = []\n",
        "for idx in selected_indices:\n",
        "  image, _ = test_dataset[idx]\n",
        "  original_images.append(image[0])\n",
        "  with torch.no_grad():\n",
        "    reconstructed_image = model(image.cuda().unsqueeze(0))\n",
        "    reconstructed_images.append(reconstructed_image.squeeze().detach().cpu().numpy().reshape(28,28))\n",
        "\n",
        "# 원본 그림, 복원된 그림 확인하기\n",
        "fig, axes = plt.subplots(num_images, 2, figsize=(8, 2+num_images))\n",
        "for i in range(num_images):\n",
        "  axes[i, 0].imshow(original_images[i], cmap='gray')\n",
        "  axes[i, 0].set_title('Original Image')\n",
        "  axes[i, 0].axis('off')\n",
        "\n",
        "  axes[i, 1].imshow(reconstructed_images[i], cmap='gray')\n",
        "  axes[i, 1].set_title('Reconstructed Image')\n",
        "  axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wID8zZJQ-lfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of latent space with respective class colors\n",
        "latent_points = []\n",
        "labels = []\n",
        "with torch.no_grad():\n",
        "  for images, targets in test_loader:\n",
        "    latent = model.encoder(images.cuda().view(images.size(0), -1))\n",
        "    latent_points.extend(latent.detach().cpu().numpy())\n",
        "    labels.extend(targets.numpy())\n"
      ],
      "metadata": {
        "id": "G_Pb4f75_rWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_points = np.array(latent_points)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "RMwHuWAbB50L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if z_dim=2:\n",
        "  from sklearn.manifold import TSME\n",
        "  # t-SNE을 적용하여 latent 표현을 2차원으로 차원을 줄이기\n",
        "  tsne = TSNE(n_components=2, random_state=0)\n",
        "  latent_2d = tsne.fit_transform(latent_points)\n",
        "else:\n",
        "  latent_2d = latent_points\n",
        "# 2차원으로 표현된 latent space 확인하기\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=test_dataset.targets, cmap='tab10', alpha=0.5)\n",
        "plt.colorbar(label('Digit class'))\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title(f't-SNE Visualization of latent space with k1, k2=[{k1},{k2}]')\n",
        "plt.savefig('1.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "ckdxnpk0B_lW",
        "outputId": "3e96fbf9-03c2-4d8b-9ecc-abc77cd8609e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'TSME' from 'sklearn.manifold' (/usr/local/lib/python3.10/dist-packages/sklearn/manifold/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4c3463567c4e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# t-SNE을 적용하여 latent 표현을 2차원으로 차원을 줄이기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlatent_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'TSME' from 'sklearn.manifold' (/usr/local/lib/python3.10/dist-packages/sklearn/manifold/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 클래스에서 그림 생성하기\n",
        "cls_num = 0\n",
        "cls_mu = np.mean(latent_points[labels==cls_num], 0)\n",
        "cls_std= np.std(latent_points[labels==cls_num], 0)\n",
        "\n",
        "x, y = np.random.multivariate_normal(cls_mu, np.diag(cls_std), 10).T\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=test_dataset.targets, cmap='tab10', alpha=0.5)\n",
        "plt.scatter(x, y, c='black', marker='+')\n",
        "plt.colorbar(label('Digit class'))\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE Visualization of latent space with k1, k2=[{k1},{k2}]')\n",
        "plt.savefig('2.png')\n"
      ],
      "metadata": {
        "id": "k5cD5XXAEQDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_latent = torch.from_numpy(np.vstack((x,y)).T).cuda().float()\n",
        "with torch.no_grad():\n",
        "  reconstructed_images = model.decoding(sampled_latent).clip(0,1).detach().cpu().numpy()\n",
        "\n",
        "fig, axes = plt.subplots(2,5, figsize=(15,6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "  ax.imshow(reconstructed_images[i, 0], 'gray')\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6GEyxEnwIeZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그림 랜덤하게 생성하기\n",
        "mu=np.mean(latent_points, 0)\n",
        "std = np.std(latent_points, 0)\n",
        "\n",
        "x, y = np.random.multivariate_normal(mu, np.diag(std), 10).T\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=test_dataset.targets, cmap='tab10', alpha=0.5)\n",
        "plt.scatter(x, y, c='black', marker='+')\n",
        "plt.colorbar(label('Digit class'))\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE Visualization of latent space with k1, k2=[{k1},{k2}]')\n",
        "plt.savefig('3.png')"
      ],
      "metadata": {
        "id": "0YloD7mp8fpY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}