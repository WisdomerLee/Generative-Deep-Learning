{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11MNShGLufkn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 그림을 폴더에서 가져오기\n",
        "folder_path = 'Images'\n",
        "images = []\n",
        "for filename in os.listdir(folder_path):\n",
        "    img_path = os.path.join(folder_path, filename)\n",
        "    img = cv2.imread(img_path)\n",
        "    img_gray_resized = cv2.resize(img, (256, 256))\n",
        "    images.append(img_gray_resized/255.0) # 255.0으로 나누는 것은 계산하는 숫자의 값을 줄이기 위함 - 계산 편의성 때문\n",
        "    # img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    # img_gray_resized = cv2.resize(img_gray, (256, 256))\n",
        "    # images.append(img_gray_resized.reshape(256, 256, 1)/255.0)\n",
        "\n",
        "# 그림 -> pytorch tensor\n",
        "images_tensor = torch.tensor(images, dtype=torch.float32).permute(0,3,1,2)\n"
      ],
      "metadata": {
        "id": "yQlifF57u0Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(folder_path)"
      ],
      "metadata": {
        "id": "trT0WXFRvkfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_dim=2"
      ],
      "metadata": {
        "id": "GIqNqCC9wl5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, z_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    # encoder\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Conv2d(3, 16, 3, stride=2, padding=1), # (N, 1, 256, 256) -> (N, 16, 128, 128)\n",
        "        nn.ReLU(true),\n",
        "        nn.Conv2d(16, 32, 3, stride=2, padding=1), # (N, 16, 128, 128) -> (N, 32, 64, 64)\n",
        "        nn.ReLU(true),\n",
        "        nn.Conv2d(32, 64, 3, stride=2, padding=1), # (N, 32, 64, 64) -> (N, 64, 32, 32)\n",
        "        nn.ReLU(true),\n",
        "        nn.Conv2d(64, 128, 3, stride=2, padding=1), # (N, 64, 32, 32) -> (N, 128, 16, 16)\n",
        "        nn.ReLU(true),\n",
        "    )\n",
        "    # Latent space\n",
        "    self.latent_space = nn.Linear(128*16*16, z_dim*2)\n",
        "    # decoder\n",
        "    self.decoder_mlp = nn.Sequential(\n",
        "        nn.Linear(z_dim, 128*16*16),\n",
        "        nn.ReLU(true)\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1), # (N, 128, 16, 16) -> (N, 64, 32, 32)\n",
        "        nn.ReLU(true),\n",
        "        nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), #  (N, 64, 32, 32) -> (N, 32, 64, 64)\n",
        "        nn.ReLU(true),\n",
        "        nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # (N, 32, 64, 64) -> (N, 16, 128, 128)\n",
        "        nn.ReLU(true),\n",
        "        nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1), # (N, 16, 128, 128) -> (N, 1, 256, 256)\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def reparameterize(self, mu, logvar):\n",
        "    std = torch.exp(logvar/2)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + eps*std\n",
        "\n",
        "  def encoding(self, x):\n",
        "    x = self.encoder(x)\n",
        "\n",
        "    x = x.reshape(x.size(0), -1)\n",
        "    latent_params = self.latent_space(x)\n",
        "\n",
        "    mu, logvar = torch.chunk(latent_params, 2, dim=1)\n",
        "    return z, mu, logvar\n",
        "\n",
        "  def decoding(self, x):\n",
        "    x = self.decoder_mlp(x).view(x.size(0), 128, 16, 16)\n",
        "    x = self.decoder(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = x.reshape(x.size(0), -1)\n",
        "    latent_params = self.latent_space(x)\n",
        "    mu, logvar = torch.chunk(latent_params, 2, dim=1)\n",
        "    z = self.reparameterize(mu, logvar)\n",
        "    x = self.decoder_mlp(z).view(x.size(0), 128, 16, 16)\n",
        "    x = self.decoder(x)\n",
        "    return x, mu, logvar\n",
        "\n"
      ],
      "metadata": {
        "id": "NGUPNvW0wnCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(x_hat, x, mea, log_var):\n",
        "  loss1 = nn.functional.binary_cross_entropy(x_hat[:, 0], x[:, 0], reduction='sum')\n",
        "  loss2 = nn.functional.binary_cross_entropy(x_hat[:, 1], x[:, 1], reduction='sum')\n",
        "  loss3 = nn.functional.binary_cross_entropy(x_hat[:, 2], x[:, 2], reduction='sum')\n",
        "  KLD = -0.5 * torch.sum(1 + log_var - mea.pow(2) - log_var.exp())\n",
        "  return loss1 + loss2 + loss3 + KLD"
      ],
      "metadata": {
        "id": "Ww1SxNNQonFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Autoencoder(z_dim).cuda()"
      ],
      "metadata": {
        "id": "sv3cBaVApNH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "iBXQfxiJpRvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs, mu, logvar = model(images_tensor.float().cuda())"
      ],
      "metadata": {
        "id": "T4fJ0kGTpax7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epochs = 1000\n",
        "train_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  running_loss = 0.0\n",
        "  optimizer.zero_grad()\n",
        "  outputs, mu, logvar = model(images_tensor.float().cuda())\n",
        "  loss = loss_function(outputs, images_tensor.float().cuda(), mu, logvar)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  running_loss += loss.item()\n",
        "  train_losses.append(running_loss)\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}')"
      ],
      "metadata": {
        "id": "YvVESue_pvdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  mu, logvar = model.encoding(images_tensor.cuda())\n",
        "  mu, logvar = mu.detach().cpu().numpy(), logvar.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "BPU4hXYsqSRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "for i in range(len(mu)):\n",
        "  cov = np.zeros((2,2))\n",
        "  cov[0, 0] = np.exp(0.5*logvar[i, 0])\n",
        "  cov[1, 1] = np.exp(0.5*logvar[i, 1])\n",
        "  pts = np.random.multivariate_normal(mu[i], cov, size=1000)\n",
        "  plt.plot(pts[:, 0], pts[:, 1], '.', alpha=0.5)\n",
        "\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Amym0utTqcM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "selected_images = images_tensor[:2]\n",
        "with torch.no_grad():\n",
        "  reconstructed_images, _, _ = model(selected_images.cuda())\n",
        "  reconstructed_images = reconstructed_images.permute(0,2,3,1).detach().cpu().numpy()\n",
        "\n",
        "fig, axes = plt.subplot(2,2, figsize=(8,8))\n",
        "for i in range(2):\n",
        "  axes[0, i].imshow(np.flip(selected_images.permute(0,2,3,1)[i].numpy(), -1))\n",
        "  axes[0, i].set_title('Original Image')\n",
        "  axes[1, i].imshow(np.flip(reconstructed_images[i], -1))\n",
        "  axes[1, i].set_title('Reconstructed Image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kye0eE6Dq_Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정 클래스에서 그림 만들기"
      ],
      "metadata": {
        "id": "we_SYNBat2t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_idx=1\n",
        "x, y = np.random.multivariate_normal(mu[cls_idx], np.diag(np.exp(0.5*logvar[cls_idx])), 10).T\n",
        "\n",
        "sampled_latent = torch.from_numpy(np.vstack((x,y)).T).cuda().float()\n",
        "\n",
        "with torch.no_grad():\n",
        "  reconstructed_images = model.decoding(sampled_latent).clip(0,1).permute(0,2,3,1).detach().cpu().numpy()\n",
        "\n",
        "fig, axes = plt.subplot(2, 5, figsize=(15, 6))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "  ax.imshow(np.flip(reconstructed_images[i], -1))\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eXHTbaeIt9l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_names = ['Monalisa', 'Starry Night', 'The Girl', 'Van Gogh']"
      ],
      "metadata": {
        "id": "ZG3kQdUkuuN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤하게 골라서 그림을 복원을 시키면 모델이 학습한 것들 기준으로 그 사이에 중첩된 무언가가 튀어나옴\n",
        "latent = torch.randn(1, z_dim).cuda()\n",
        "with torch.no_grad():\n",
        "  interpolated_images = model.decoding(latent).clip(0, 1).permute(0,2,3,1).detach().cpu().numpy()\n",
        "plt.subplot(121)\n",
        "for i in range(len(mu)):\n",
        "  cov = np.zeros((2,2))\n",
        "  cov[0,0] = np.exp(0.5*logvar[i,0])\n",
        "  cov[1,1]= np.exp(0.5*logvar[i, 1])\n",
        "  pts = np.random.multivariate_normal(mu[i], cov, size=1000)\n",
        "  plt.plot(pts[:, 0], pts[:, 1], label=img_names[i])\n",
        "\n",
        "plt.scatter(latent.detach().cpu().numpy()[0,0], latent.datech().cpu().numpy()[0,1], label='sample')\n",
        "plt.xlim([-10, 10])\n",
        "plt.ylim([-10, 10])\n",
        "plt.legend()\n",
        "plt.subplot(122)\n",
        "plt.imshow(np.flip(interpolated_images[0], -1))"
      ],
      "metadata": {
        "id": "Yn22Drt90Ag3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}