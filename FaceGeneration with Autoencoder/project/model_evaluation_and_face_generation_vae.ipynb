{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "이번엔 바로 학습된 모델의 파라미터를 받아와서 그 모델을 평가해보고, 얼굴을 만들어보기"
      ],
      "metadata": {
        "id": "jjYAMoxw_q0f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kflPEAIe_qVQ"
      },
      "outputs": [],
      "source": [
        "!gdown --id liUkepsRdaADfCnczvx2-jkcT2bHLUyPd\n",
        "# 이번엔 학습 파라미터를 바로 받아보자"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLQottK7DHlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "I2xul0vxDOFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show(img, renorm=False, nrow=8, interpolation='bicubic'):\n",
        "  if renorm:\n",
        "    img = img*0.5 + 0.5\n",
        "  img_grid = torchvision.utils.make_grid(img, nrow=nrow).numpy()\n",
        "  plt.figure()\n",
        "  plt.imshow(np.transpose(img_grid, (1,2,0)), interpolation=interpolation)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "sbRLqp5WDpxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = 'data_faces/img_align_celeba'\n",
        "img_list = os.listdir(root)\n",
        "print(len(img_list))"
      ],
      "metadata": {
        "id": "KwuaU2edEDXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "  def __init__(self, image_size=128, latent_dim=512):\n",
        "    super(VAE, self).__init__()\n",
        "\n",
        "    # Encoder\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten()\n",
        "    )\n",
        "    # 평균, 분산을 확인할 수 있는 파라미터 정의\n",
        "    self.fc_mu = nn.Linear(256*(image_size // 16) * (image_size // 16), latent_dim)\n",
        "    self.fc_logvar = nn.Linear(256*(image_size // 16) * (image_size // 16), latent_dim)\n",
        "\n",
        "    # Decoder\n",
        "    self.decoder_input = nn.Linear(latent_dim, 256 * (image_size // 16) * (image_size // 16))\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.image_size = image_size\n",
        "\n",
        "  def encoder(self, x):\n",
        "    x = self.encoder(x)\n",
        "    mu, logvar = self.fc_mu(x), self.fc_log_var(x)\n",
        "    return mu, logvar\n",
        "\n",
        "  def reparameterize(self, mu, logvar):\n",
        "    std = torch.exp(0.5*logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu * eps * std\n",
        "\n",
        "  def decoder(self, z):\n",
        "    x = self.decoder_input(z)\n",
        "    x = x.view(-1, 256, (self.image_size // 16), (self.image_size // 16))\n",
        "    x = self.decoder(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    mu, logvar = self.encoder(x)\n",
        "    z = self.reparameterize(mu, logvar)\n",
        "    reconstructed_x = self.decoder(z)\n",
        "    return reconstructed_x, mu, logvar\n"
      ],
      "metadata": {
        "id": "wDaY2wLcEKqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re_size = 128\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(size=(re_size, re_size), interpolation=Image.BICUBIC),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "batch_size = 64\n",
        "celeba_data = datasets.ImageFolder('./data_faces', transform=transform)\n",
        "celeba_loader = DataLoader(celeba_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "Z4RSWoySGJgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "XRrU5E9VG5vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE().to(device)\n",
        "model.load_state_dict(torch.load('celeba_vae.pth'))\n",
        "model.eval()\n",
        "# 이미 훈련된 모델을 쓰기 때문에 훈련을 할 필요 없이 해당 모델을 사용하면 됨\n",
        "# 모델은 훈련하기 위해 기본적으로 gradient를 계산하는데, 평가 형태로 두면 gradient를 계산하지 않게 되어 모델의 연산이 훨씬 더 빠르게 됨\n"
      ],
      "metadata": {
        "id": "7wxHug6DKUVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그림 생성\n",
        "batch, _ = next(iter(celeba_loader))\n"
      ],
      "metadata": {
        "id": "HYhiNrJzKcYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstruction, _, _ = model(batch.cuda())\n",
        "display_grid(batch, figsize=(8,8))\n",
        "plt.savefig('vae_training_data.png', bbox_inches='tight', pad_inches=0, dpi=156)\n",
        "plt.show()\n",
        "display_grid(reconstruction.to('cpu'), figsize=(8,8))\n",
        "plt.savefig('vae_reconstruction.png', bbox_inches='tight', pad_inches=0, dpi=156)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "83ORXla2MzUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 원본과 복원된 그림을 보면 복원된 그림의 품질이 아주 선명하진 않기도 함, 해당 그림의 품질을 더 높일 수도 있음\n",
        "sampled_latents = torch.randn(len(batch), 512).cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "  reconstructed_x = model.decode(sampled_latents)\n",
        "\n",
        "display_grid(reconstructed_x.detach().clip(0,1).cpu(), figsize=(8,8))"
      ],
      "metadata": {
        "id": "44qxmUkPM-VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector Interpolation\n",
        "batch, _ = next(iter(celeba_loader))\n",
        "display_grid(batch, figsize=(8,8))\n"
      ],
      "metadata": {
        "id": "ub5xVX6NNLbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "target_images = [0, 2]\n",
        "reconstructed_x, mu, logvar = model(batch[target_images].cuda())"
      ],
      "metadata": {
        "id": "7lhp5mT0NVbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latents = model.reparameterize(mu,logvar).detach().cpu().numpy()\n",
        "\n",
        "vectors = []\n",
        "ratios = np.linspace(0,1, mum=10)\n",
        "\n",
        "# Vector interpolation\n",
        "for ratio in ratios:\n",
        "  v = (1.0 - ratio) * latents[0]+ ratio * latents[1]\n",
        "  vectors.append(v)\n",
        "\n",
        "vectors = np.asarray(vectors)\n",
        "\n",
        "with torch.no_grad():\n",
        "  reconstructed_x = model.decode(torch.from_numpy(vectors).cuda()).permute(0,2,3,1).detach().clip(0,1).cpu().numpy()\n",
        "\n",
        "\n",
        "  fig, axes = plt.subplots(1,10, figsize=(20, 2))\n",
        "  for i in range(10):\n",
        "    axes[i].imshow(reconstructed_x[i])\n",
        "    axes[i].axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "syOsQznJKHkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Attributes Modification\n",
        "# 이것을 적용하려면 그림에 어떤 속성이 있는지를 같이 불러들여서 그림과 그 그림의 속성을 같이 맞추어 주어야 함!\n",
        "# 그래서 아래와 같이 데이터 셋을 정의하고,\n",
        "\n",
        "class CelebADataset(Dataset):\n",
        "  def __init__(self, data, labels, classes, transform=None):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "    self.classes = classes\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(os.path.join('data_faces', 'img_align_celeba', self.data[idx])).convert('RGB')\n",
        "    label = torch.Tensor(self.labels[idx, [39, 20, 22, 2, 31, 15]].astype('uint8'))\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    sample = {'images': img, 'labels': label}\n",
        "    return sample\n"
      ],
      "metadata": {
        "id": "oY4vHQvpQbI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('list_attr_celeba.csv')\n",
        "df.head()\n",
        "# 어떤 특성이 있는지 csv로 어느 그림에 어느 속성들이 들어있는지 확인한 뒤에"
      ],
      "metadata": {
        "id": "Dt07hguiRKO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = df.values\n",
        "\n",
        "values[:, 1:] += 1\n",
        "values[:, 1:]/=2\n",
        "\n",
        "# -1,과 1로 된 값을 0과 1로 맞춰주기 위해 위와 같이 처리하는 것\n",
        "\n",
        "classes = df.columns[1:]"
      ],
      "metadata": {
        "id": "SzbYMvmQRfQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values.shape"
      ],
      "metadata": {
        "id": "_kvcscgMTIoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes.shape"
      ],
      "metadata": {
        "id": "-kWR_luATLce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes[[39, 20, 22, 2, 31, 15]]\n",
        "# 특징들 중에 특정 타입만 뽑아보기! 여섯개의 특징을 확인"
      ],
      "metadata": {
        "id": "smvjXC64S-0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(values[:, 15])"
      ],
      "metadata": {
        "id": "JweHPec1Ufcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_idxs = [39, 20, 22, 2, 31, 15]\n",
        "att_names = classes[att_idxs]\n",
        "attnames"
      ],
      "metadata": {
        "id": "acj_E3q-UiU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_idx=20+1"
      ],
      "metadata": {
        "id": "TwbCyy91Uv1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(os.path.join('outputs', classes[att_idx-1]+ 'neg_pos.npy')):\n",
        "  neg_data = CelebADataset(values[values[:, att_idx]==0, 0], values[values[:, att_idx]==0, 1:], classes, transform)\n",
        "  pos_data = CelebADataset(values[values[:, att_idx]==1, 0], values[values[:, att_idx]==1, 1:], classes, transform),\n",
        "\n",
        "  neg_loader = DataLoader(neg_data, batch_size=batch_size)\n",
        "  pos_loader = DataLoader(pos_data, batch_size=batch_size)\n",
        "\n",
        "  print('Negative latent')\n",
        "  neg_latent = torch.zeros(512)\n",
        "  cpt = 0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(neg_loader):\n",
        "      imgs, labels = data['images'].float().to(device), data['labels'].long().to(device)\n",
        "\n",
        "      recon_img, mu, logvar = model(imgs)\n",
        "      neg_latent += torch.sum(model.reparameterize(mu, logvar).detach().cpu(), 0)\n",
        "      cpt+= 64\n",
        "      if batch_idx % 100 == 0:\n",
        "        print(f'Step[{batch_idx+1}/{len(neg_loader)}]')\n",
        "\n",
        "  neg_latent/=cpt\n",
        "  print('Positive latent')\n",
        "  pos_latent = torch.zeros(512)\n",
        "  cpt=0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(pos_loader):\n",
        "      imgs, labels = data['images'].float().to(device), data['labels'].long().to(device)\n",
        "\n",
        "      recon_img, mu, logvar = model(imgs)\n",
        "      pos_latent += torch.sum(model.reparameterize(mu, logvar).detach().cpu(), 0)\n",
        "      cpt+= 64\n",
        "      if batch_idx % 100 == 0:\n",
        "        print(f'Step[{batch_idx+1}/{len(neg_loader)}]')\n",
        "  pos_latent/=cpt\n",
        "  V = (pos_latent-neg_latent).detach().cpu().numpy()[0]\n",
        "  V /= np.linalg.norm(V)\n",
        "  np.save(os.path.join('outputs', classes[att_idx-1]+'neg_pos.npy'), V)\n",
        "else:\n",
        "  V = np.load(os.path.join('outputs', classes[att_idx=1]+'neg_pos.npy'))"
      ],
      "metadata": {
        "id": "VCpG_RUPUykF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_cls = np.random.choice(2)\n",
        "idxs = np.where(values[:, att_idx]==label_cls)[0]\n",
        "sample_idx = idxs[np.random.choice(len(idxs))]\n",
        "\n",
        "img = Image.open(os.path.join('data_faces', 'img_align_celeba', values[sample_idx, 0])).convert('RGB')\n",
        "img = transform(img).unsqueeze(0).float().cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "  reconstructions, mu, logvar = model(img)\n",
        "  reconstructions = reconstructions.datach().cpu().clip(0, 1)\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(img.permute(0,2,3,1).cpu().numpy()[0])\n",
        "plt.axis('off')\n",
        "plt.title('Original')\n",
        "plt.subplot(122)\n",
        "plt.imshow(reconstructions.permute(0,2,3,1).cpu().numpy()[0])\n",
        "plt.axis('off')\n",
        "plt.title('Original '+ classes[att_idx-1]+'%d'%(label_cls))\n"
      ],
      "metadata": {
        "id": "3YxBsW1zXhal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latents = model.reparameterize(mu, logvar).detach().cpu().numpy()\n",
        "\n",
        "vectors = []\n",
        "ratios = np.linspace(0, 1, num=10)\n",
        "\n",
        "for ratio in ratios:\n",
        "  if label_cls==0:\n",
        "    v = latents[0] + ratio * V\n",
        "  else:\n",
        "    v = latents[0] - ratio * V\n",
        "\n",
        "  vectors.append(v)\n",
        "\n",
        "vectors = np.asarray(vectors)\n",
        "\n",
        "reconstructed_x = model.decode(torch.from_numpy(vectors).cuda()).permute(0,2,3,1).detach().clip(0,1).cpu().numpy()\n",
        "\n",
        "#\n",
        "fig, axes = plt.subplot(1, 10, figsize=(20, 20))\n",
        "for i in range(10):\n",
        "  axes[i].imshow(reconstructed_x[i])\n",
        "  axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "olJu7ci2YbEv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}