{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvPq-JVn9_G0"
      },
      "outputs": [],
      "source": [
        "# Mnist라는 숫자를 그림으로 표현한 것을 학습시킬 것\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_dim=128"
      ],
      "metadata": {
        "id": "YKMUfP2r-TD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# autoencoder model 정의\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, z_dim=128):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.encoder = torch.nn.Sequential(\n",
        "        torch.nn.Linear(28*28, 256),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(256, 128),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(128, z_dim),\n",
        "    )\n",
        "    self.decoder = torch.nn.Sequential(\n",
        "        torch.nn.Linear(z_dim, 256),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(256, 28*28),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    x = x.view(x.size(0), 28, 28)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "p74EurUb-Uf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset 불러오기! > 아래의 내용은 기본적으로 tensor로 변환만 하고 있음 > MNIST는 이미 데이터 기본 전처리가 되어있기 때문\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "w5GYFKUYA8jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNIST(route='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(route='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "ow8Z8rE02hp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 클래스별로 저장된 파일을 담을 dict 만들기\n",
        "samples = {}\n",
        "for i in range(10):\n",
        "  samples[i] = None\n",
        "\n",
        "cpt = 0\n",
        "\n",
        "# 훈련용 데이터에 들어있는 정보를 클래스별로 저장해두기\n",
        "for data, target in train_dataset:\n",
        "  if samples[target] is None:\n",
        "    samples[target] = data\n",
        "    cpt += 1\n",
        "    if cpt == 10:\n",
        "      break\n",
        "\n",
        "# sample 그리기\n",
        "fig, axes = plt.subplots(1, 10, figsize=(12, 3))\n",
        "for i in range(10):\n",
        "  axes[i].imshow(samples[i][0], cmap='gray')\n",
        "  axes[i].set_title(f'Class {i}')\n",
        "  axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x17TFLaS37Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader 만들기\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "#\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "-b9O7NgW4ysL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )"
      ],
      "metadata": {
        "id": "qrnxvIxP7rtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "#AutoEncoder model을 이용하여 모델 객체 만들고\n",
        "# 특정 device로 불러오기 - cpu, gpu 중에 선택\n",
        "model = Autoencoder().to(device)\n",
        "\n",
        "# optimizer 객체 만들기\n",
        "# 일반적으로 Adam을 많이 사용함..\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# loss 정의\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "PXBTdPJr71R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor의 모습 확인할 것 - 이것은 코드를 작성하는 과정에서만 잠시 임의로 쓰이는 부분\n",
        "# I = torch.rand((1,1,28,28)).cuda()\n",
        "# with torch.no_grad():\n",
        "#  print(model(I).shape)"
      ],
      "metadata": {
        "id": "eghAKmw18Xl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련\n",
        "num_epochs = 100\n",
        "train_losses = []\n",
        "for epoch in range[num_epochs]:\n",
        "  running_loss = 0.0\n",
        "  for images, _ in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images.cuda())\n",
        "    loss = nn.functional.binary_cross_entropy(outputs.reshape(-1, 1), images.cuda().reshape(-1, 1), reductions='sum')\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item() * images.size(0)\n",
        "  train_loss = running_loss / len(train_loader.dataset)\n",
        "  train_losses.append(train_loss)\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "IuSluyG38pgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random images를 선택하고 그 테스트 이미지들을 재구성하기\n",
        "num_images = 5\n",
        "\n",
        "selected_indices = torch.randint(len(test_dataset), size=(num_images,))\n",
        "reconstructed_images = []\n",
        "original_images = []\n",
        "for idx in selected_indices:\n",
        "  image, _ = test_dataset[idx]\n",
        "  original_images.append(image[0])\n",
        "  with torch.no_grad():\n",
        "    reconstructed_image = model(image.cuda().unsqueeze(0))\n",
        "    reconstructed_images.append(reconstructed_image.squeeze().detach().cpu().numpy().reshape(28,28))\n",
        "\n",
        "# 원본 그림, 복원된 그림 확인하기\n",
        "fig, axes = plt.subplots(num_images, 2, figsize=(8, 2+num_images))\n",
        "for i in range(num_images):\n",
        "  axes[i, 0].imshow(original_images[i], cmap='gray')\n",
        "  axes[i, 0].set_title('Original Image')\n",
        "  axes[i, 0].axis('off')\n",
        "\n",
        "  axes[i, 1].imshow(reconstructed_images[i], cmap='gray')\n",
        "  axes[i, 1].set_title('Reconstructed Image')\n",
        "  axes[i, 1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wID8zZJQ-lfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot of latent space with respective class colors\n",
        "latent_points = []\n",
        "labels = []\n",
        "with torch.no_grad():\n",
        "  for images, targets in test_loader:\n",
        "    latent = model.encoder(images.cuda().view(images.size(0), -1))\n",
        "    latent_points.extend(latent.detach().cpu().numpy())\n",
        "    labels.extend(targets.numpy())\n"
      ],
      "metadata": {
        "id": "G_Pb4f75_rWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_points = np.array(latent_points)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "RMwHuWAbB50L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSME\n",
        "# t-SNE을 적용하여 latent 표현을 2차원으로 차원을 줄이기\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "latent_2d = tsne.fit_transform(latent_points)\n",
        "\n",
        "# 2차원으로 표현된 latent space 확인하기\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=test_dataset.targets, cmap='tab10', alpha=0.5)\n",
        "plt.colorbar(label('Digit class'))\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE Visualization of latent space')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "ckdxnpk0B_lW",
        "outputId": "3e96fbf9-03c2-4d8b-9ecc-abc77cd8609e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'TSME' from 'sklearn.manifold' (/usr/local/lib/python3.10/dist-packages/sklearn/manifold/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4c3463567c4e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# t-SNE을 적용하여 latent 표현을 2차원으로 차원을 줄이기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlatent_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'TSME' from 'sklearn.manifold' (/usr/local/lib/python3.10/dist-packages/sklearn/manifold/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2군데의 랜덤한 latent point를 골라보기\n",
        "selected_indices = np.random.choice(len(latent_points), 2, replace=false)\n",
        "selected_latent = latent_points[selected_indices]\n",
        "selected_latent_2d = latent_2d[selected_indices]\n",
        "selected_labels = lables[selected_indices]"
      ],
      "metadata": {
        "id": "k5cD5XXAEQDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# latent space에서 class color를 입혀 어느 클래스고 어느 latent 공간에 있는지 확인해보기\n",
        "plt.scatter(latent_2d[:, 0], latent_2d[:, 1], label='Selected Latent Points')\n",
        "plt.scatter(selected_latent_2d[:, 0], selected_latent_2d[:, 1], label='Selected Latent Points')\n",
        "plt.xlabel('Latent Dim 1')\n",
        "plt.ylabel('Latent Dim 2')\n",
        "plt.title('Latent Space with Selected Latent Points')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6GEyxEnwIeZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent1, latent2 = torch.from_numpy(selected_latent)\n",
        "\n",
        "interpolation_points = torch.zeros((10, z_dim))\n",
        "for i in range(10):\n",
        "  interpolation_points[i] = latent1 + (latent2 - latent1) * 1 / 9\n"
      ],
      "metadata": {
        "id": "awvTMzSrI_4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선택된 곳의 latent point를 decode해보기\n",
        "with torch.no_grad():\n",
        "  decoded_images = model.decoder(interpolation_points.cuda()).detach().cpu().numpy().reshape(-1, 28, 28)"
      ],
      "metadata": {
        "id": "p2Sid-tyJXay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decoded images\n",
        "fig, axes = plt.subplots(1, 10, figsize=(12, 3))\n",
        "for i in range(10):\n",
        "  axes[i].imshow(decoded_images[i], cmap='gray')\n",
        "  axes[i].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z-rOKqWCJm0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}