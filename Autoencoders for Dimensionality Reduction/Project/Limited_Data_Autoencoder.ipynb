{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i3Qzqppl-YY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 그림 내용을 불러와서 회색으로 변경하고, 크기를 일정하게 맞추기\n",
        "folder_path = \"Images\"\n",
        "images = []\n",
        "for filename in os.listdir(folder_path):\n",
        "  img = cv2.imread(os.path.join(folder_path, filename))\n",
        "  img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  img_gray_resized = cv2.resize(img_gray, (256, 256))\n",
        "  images.append(img_gray_resized/255.0)\n",
        "\n",
        "# 그림을 PyTorch tensor로 변경\n",
        "images_tensor = torch.tensor(images, dtype=torch.float32).unsqueeze(1) # unsqueeze로 차원을 하나 더 함 - 색깔이 회색으로 바뀌었기 때문에 색깔에 대한 차원을 맨 앞에 1개로 지정, 만약 RGB의 3개의 값이 있었다면 unsqueeze(3)이 추가되었을 것\n",
        "\n"
      ],
      "metadata": {
        "id": "7nn2uIw6myjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image tensor의 차원의 숫자는 해당 tensor로 묶인 그림의 갯수, 색깔 채널의 숫자, 그림의 크기(가로? 세로?)가 순서대로\n",
        "images_tensor.shape\n"
      ],
      "metadata": {
        "id": "jBF_OQ34ng2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# autoencoder model을 정의\n",
        "class Audoencoder(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Autoencoder, self).__init__() # 이것은 반드시 꼭 해야 제대로 동작함\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.Linear(256*256, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 2)\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(2, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 256*256),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = x.view(x.size[0], -1) # 1차원으로 그림의 내용을 정리 flatten으로 같은 결과를 얻을 수 있음!\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "    x = x.view(x.size[0], 1, 256, 256) # 원래의 차원으로 다시 돌려주기\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "1Rq0rK81oR4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 초기화\n",
        "model = Autoencoder()"
      ],
      "metadata": {
        "id": "Q0kzu_Xyp6PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss, optimizer 함수 설정\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "GkccAi83p-B3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_tensor.shape"
      ],
      "metadata": {
        "id": "rlbjOjnxrkhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련\n",
        "num_epochs = 100\n",
        "train_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "  running_loss = 0.0\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(images_tensor)\n",
        "  loss = criterion(outputs, images_tensor)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  running_loss += loss.item()\n",
        "  train_losses.append(running_loss)\n",
        "  print(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch+1, num_epochs, running_loss))\n",
        "\n"
      ],
      "metadata": {
        "id": "4LWYQ5CnrrHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 과정에서 loss 값이 제대로 줄어드는지 확인 -> 만약 줄어드는 과정이 이상하거나 하면 훈련 방식 혹은 데이터 갯수 혹은 훈련의 숫자 등의 문제가 있으므로 파라미터 등을 조정하고 다시 훈련시켜야 함\n",
        "plt.plot(train_losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qh2nbvm0sMT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# latent space에서의 위치를 표현해보기\n",
        "with torch.no_grad():\n",
        "  latent_points = model.encoder(images_tensor.view(images_tensor.size[0], -1)).numpy()\n",
        "\n",
        "plt.scatter(latent_points[:, 0], latent_points[:, 1], c=np.arange(len(images)))\n",
        "plt.xlabel('Latent Dim 1')\n",
        "plt.ylabel('Latent Dim 2')\n",
        "plt.title('Scatter plot of Latent Space')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bVSn3_-DstLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선택한 그림을 다시 그려보기 - 그림 재건 - 이것은 그림을 학습시키는 과정에서 매우 중요한 부분을 담당함\n",
        "selected_images = images_tensor[:2]\n",
        "with torch.no_grad():\n",
        "  reconstructed_images = model(selected_images.view(selected_images.size[0], -1)).numpy()\n",
        "\n",
        "# 원본 그림과 다시 복원된 그림을 비교\n",
        "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
        "for i in range(2):\n",
        "  axes[0, i].imshow(selected_images[i].squeeze(), cmap='gray')\n",
        "  axes[0, i].set_title('Original Image')\n",
        "  axes[1, i].imshow(reconstructed_images[i].reshape(256, 256), cmap='gray')\n",
        "  axes[1, i].set_title('Reconstructed Image')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YgT7OieWuUZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선택된 두 latent space의 공간의 포인트를 interpolation?\n",
        "latent1 = model.encoder(selected_images[0].view[1, -1]).detach().numpy()\n",
        "latent2 = model.encoder(selected_images[1].view[1, -1]).detach().numpy()\n",
        "interpolation_points = np.zeros([10, 2])\n",
        "for i in range(10):\n",
        "  interpolation_points[i] = latent1 + (latent2-latent1)*i/9\n",
        "\n"
      ],
      "metadata": {
        "id": "kiSJHRszwza2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# latent point의 위치 변화를 찍어보기\n",
        "plt.scatter(interpolation_points[:, 0], interpolation_points[:, 1], color='green', label='Interpolated Points')\n",
        "plt.scatter(latent_points[:, 0], latent_points[:, 1], c=np.arange(len(images)))\n",
        "plt.legend()\n",
        "plt.title('Latent Space with selected and interpolated points')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0moVxtf3xUzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  interpolated_images = model.decoder(torch.tensor(interpolation_points).float()).numpy()"
      ],
      "metadata": {
        "id": "fM83l9t3yBtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중간에 내적인 부분들의 그림을 그려보게 시키기\n",
        "fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
        "for i in range(10):\n",
        "  axes[i].imshow(interpolated_images[i].reshape(256, 256), cmap='gray')\n",
        "  axes[i].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Gzgop1xyNZh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
